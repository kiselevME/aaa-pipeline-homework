{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97067b1b-b81f-4a8d-930e-f98923ed2c98",
   "metadata": {},
   "source": [
    "# Home Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c54bc-6d4d-4ab5-afa7-8b4b427f2830",
   "metadata": {},
   "source": [
    "В этой работе будем иследовать одну из популярнейших рекомендательных моделей - **Latent Factor Model** - https://arxiv.org/pdf/1912.04754. \n",
    "\n",
    "Перед выполнением задания нужно убедиться, что прогоняется бейзлайн. Для этого:\n",
    "1) Скачайте  файлы - **node2name.json** и **clickstream.parque** с необходимыми данными\n",
    "2) Положите в репозиторий ноутбука и запустите код\n",
    "\n",
    "В этой работе вам нужно:\n",
    "1) перебрать параметры модели - edim,batch_size, lr, epoch , num_negatives -   (по **1 балу - 5 балов**) \n",
    "2) Тип OPTIMIZER_NAME - (**4 бала за 5 оптимизаторов**)\n",
    "3) На основе имеющихся данных собрать лучшую модель (по **precision@30**) и рассчитать ее метрики (**4 бала**)\n",
    "4) Попробовать другие модели (например  als - https://benfred.github.io/implicit/ , gru4rec, sasrec  ) - за sasrec на хорошем уровне сразу **10 балов**. За другие модели по **3 бала**\n",
    "5) По окончанию работы в mlflow настроить графики для сравнения моделей. Можно проявить фантазию, но обязательно должно быть сравнение с бейзлайном (данный ноутбук) против других моделей\n",
    "6) В mlflow залогировать последнюю версию ноутбука - необходимое условия. Либо в github, но тогда прикрепить ссылку в [mlflow](http://84.201.128.89:90/) . Эксперимент в формате - **homework-\\<name\\>**\n",
    "7) Доп балы (**20 баллов**) тому у кого будет наибольший скор на тесте. Но ваш ноутбук должен прогонятся и быть вопроизводимым.\n",
    "\n",
    "Суммарно за работу **20 балов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ab3a6e-5593-49ee-bca6-12d224fd68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/node2name.json', 'r') as f:\n",
    "    node2name = json.load(f)\n",
    "\n",
    "node2name = {int(k):v for k,v in node2name.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d523edb6-2c82-4f46-92c6-a8b2812ce05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f26a69-7a82-42d5-8a46-309178194a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('data/clickstream.parque')\n",
    "df = df.head(100_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8af31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9b6966-efcb-402e-b96d-c2a25b26c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = df['event_date']< df['event_date'].max() - pd.Timedelta('2 day')\n",
    "df['names'] = df['node_id'].map(node2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c988e382-1568-47ce-a3f7-ccbeb00ce4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a64aab-a44e-400f-93e7-ef0fb2646b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cooks = df[df['is_train']]['cookie_id'].unique()\n",
    "train_items = df[df['is_train']]['node_id'].unique()\n",
    "\n",
    "\n",
    "df = df[(df['cookie_id'].isin(train_cooks)) & (df['node_id'].isin(train_items))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa39801-c8df-4e34-b296-e87d0e4f7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indes, index2user_id = pd.factorize(df['cookie_id'])\n",
    "df['user_index'] = user_indes\n",
    "\n",
    "node_indes, index2node = pd.factorize(df['node_id'])\n",
    "df['node_index'] = node_indes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04782b66-dd86-49cb-89e9-4ded7a4eee82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['node_index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2348281f-2833-43d7-b7bc-7323a18e08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b61d95-a8bd-42a9-bf00-b21b543ea5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96611, 7), (3333, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = df[df['is_train']], df[~df['is_train']]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13349dd1-0e15-4879-bb1c-204c425984be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import random \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class RecDataset(Dataset):\n",
    "    def __init__(self, users, items, item_per_users):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.item_per_users=item_per_users\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        user = self.users[i]\n",
    "        return torch.tensor(user), torch.tensor(self.items[i]), self.item_per_users[user]\n",
    "\n",
    "\n",
    "class LatentFactorModel(nn.Module):\n",
    "    def __init__(self, edim, user_indexes, node_indexes):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        self.edim = edim\n",
    "        self.users = nn.Embedding(max(user_indexes) + 1, edim)\n",
    "        self.items = nn.Embedding(max(node_indexes) + 1, edim)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_embedings = self.users(users).reshape(-1, self.edim )\n",
    "        item_embedings = self.items(items)\n",
    "        res = torch.einsum('be,bne->bn', user_embedings, item_embedings)\n",
    "        return res \n",
    "\n",
    "    def pred_top_k(self, users, K=10):\n",
    "        user_embedings = self.users(users).reshape(-1, self.edim )\n",
    "        item_embedings = self.items.weight\n",
    "        res = torch.einsum('ue,ie->ui', user_embedings, item_embedings)\n",
    "        return torch.topk(res, K, dim=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def collate_fn(batch, num_negatives, num_items):\n",
    "    users, target_items, users_negatives = [],[], []\n",
    "    for triplets in batch:\n",
    "        user, target_item, seen_item = triplets\n",
    "        \n",
    "        users.append(user)\n",
    "        target_items.append(target_item)\n",
    "        user_negatives = []\n",
    "        \n",
    "        while len(user_negatives)< num_negatives:\n",
    "            candidate = random.randint(0, num_items)\n",
    "            if candidate not in seen_item:\n",
    "                user_negatives.append(candidate)\n",
    "                \n",
    "        users_negatives.append(user_negatives)\n",
    "                \n",
    "    \n",
    "    positive = torch.ones(len(batch), 1)       \n",
    "    negatives = torch.zeros(len(batch), num_negatives)\n",
    "    labels = torch.hstack([positive, negatives])\n",
    "    # print(torch.tensor(target_items))\n",
    "    # print(users_negatives)\n",
    "    items = torch.hstack([torch.tensor(target_items).reshape(-1, 1), torch.tensor(users_negatives)])\n",
    "    return torch.hstack(users), items, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14069993-68c8-424c-953f-54d19fcb71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2seen = df_train.groupby('user_index')['node_index'].agg(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a6c714-9c4d-4020-bc02-3e657e202992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033e757296f247a7885fa08e440d06aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 50_000\n",
    "NUM_NEGATIVES = 5\n",
    "EDIM = 128\n",
    "EPOCH = 10\n",
    "OPTIMIZER_NAME = 'Adam'\n",
    "LR = 1\n",
    "\n",
    "train_dataset = RecDataset(df_train['user_index'].values, df_train['node_index'], user2seen)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(train_dataset, shuffle=True,num_workers=0, batch_size=BATCH_SIZE,collate_fn=lambda x: collate_fn(x, NUM_NEGATIVES, max(df['node_index'].values)))\n",
    "\n",
    "\n",
    "model = LatentFactorModel(EDIM, user_indes, node_indes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), LR)\n",
    " \n",
    "bar = tqdm(total = EPOCH )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4819823d-a5ff-4ab0-b610-a12e201ed796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeac266558d4acab2dd5c2b08187901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16aa7a55414446518cecb948c50926bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad9f33e50e24b87b1507cdc0dcab21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ea634116e94978b328c1b4e1836411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fde55f5947a459caa263ce21bdb5ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9811bfd9ba491497cdcea5f008f24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17917fdc5f194bc79c16859885f99f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5dffc0847c4ce79d209edc6fd98f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0558b32075724d469ee3aa0856238067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ba528b95cc4138873e2e42f1cd4a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(EPOCH):\n",
    "    bar_loader = tqdm(total = len(dataloader) ,)\n",
    "    losses = []\n",
    "    for i in dataloader:\n",
    "        users, items, labels = i\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(users, items)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, labels\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bar_loader.update(1)\n",
    "        bar_loader.set_description(f'batch loss - {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    bar.update(1)\n",
    "    bar.set_description(f'epoch loss - {sum(losses)/len(losses)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd49d632-5c65-46b5-9f4b-f22cb3ff7e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Кузов',\n",
       " 'root -> Услуги -> Предложения услуг -> Красота, здоровье -> СПА-услуги, массаж',\n",
       " 'root -> Услуги -> Предложения услуг -> Красота, здоровье -> СПА-услуги, массаж',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Система охлаждения',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Система охлаждения',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Система охлаждения']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER = 0\n",
    "\n",
    "preds = list(model.pred_top_k(torch.tensor([USER]), 10)[1][0].numpy())\n",
    "df[(df['user_index'] == USER) & (df['node_index'].isin(user2seen[USER]))]['names'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "524c7c03-972a-43ef-baa3-8575a60def25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['root -> Услуги -> Предложения услуг -> Красота, здоровье -> СПА-услуги, массаж',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Система охлаждения',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Запчасти -> Для автомобилей -> Кузов',\n",
       " 'root -> Транспорт -> Автомобили -> Универсал',\n",
       " 'root -> Услуги -> Предложения услуг -> Уборка -> Генеральная уборка',\n",
       " 'root -> Недвижимость -> Дома, дачи, коттеджи -> Купить -> Дом',\n",
       " 'root -> Транспорт -> Автомобили -> С пробегом -> Mercedes-Benz -> S-класс',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Тюнинг',\n",
       " 'root -> Транспорт -> Запчасти и аксессуары -> Шины, диски и колёса -> Легковые шины',\n",
       " 'root -> Транспорт -> Автомобили -> Внедорожник']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node2name[index2node[i]] for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35dc873f-0223-4404-83fe-ab290dc541f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "\n",
    "test_users = df_test['user_index'].unique()\n",
    "\n",
    "\n",
    "preds = model.pred_top_k(torch.tensor(test_users), K)[1].numpy()\n",
    "df_preds = pd.DataFrame({'node_index': list(preds), 'user_index': test_users, 'rank': [[j for j in range(0, K)]for i in range(len(preds))]})\n",
    "\n",
    "df_preds = df_preds.explode(['node_index', 'rank']).merge(\n",
    "    df_test[['user_index', 'node_index']].assign(relevant=1).drop_duplicates(),\n",
    "    on = ['user_index', 'node_index'],\n",
    "    how='left' ,\n",
    ")\n",
    "df_preds['relevant'] = df_preds['relevant'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca5c9145-26b1-4e64-aabf-ac82e1ac4bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.815592203898051, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_hitrate(df_preds, K):\n",
    "    return  df_preds[df_preds['rank']<K].groupby('user_index')['relevant'].max().mean()\n",
    "\n",
    "def calc_prec(df_preds, K):\n",
    "    return  (df_preds[df_preds['rank']<K].groupby('user_index')['relevant'].mean()).mean()\n",
    "    \n",
    "hitrate = calc_hitrate(df_preds, K)\n",
    "\n",
    "hitrate, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debe9ed6-6ebe-4945-a404-407146c8e49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04387806096951524"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_prec(df_preds, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7bec888-1493-4851-a23d-d0bad1e62813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['node_index'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43cc796e-1235-47f1-8466-a59755569010",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_popular = df_train[['node_index']].assign(v=1).groupby('node_index').count().reset_index().sort_values(by='v').tail(K)['node_index'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba04dcf0-1d0b-4580-9171-d6bbd5221693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'root -> Транспорт -> Автомобили -> Внедорожник'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2name[index2node[top_popular[-1]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5439d",
   "metadata": {},
   "source": [
    "# Базелин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c88a32e5-f0ca-483f-85e6-da90d3d16799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836581709145427"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds_top_poplular = pd.DataFrame({'node_index': [list(top_popular) for i in test_users], 'user_index': test_users, 'rank': [[j for j in range(0, K)]for i in range(len(test_users))]})\n",
    "\n",
    "\n",
    "df_preds_top_poplular = df_preds_top_poplular.explode(\n",
    "    ['node_index', 'rank']\n",
    ").merge(\n",
    "    df_test[['user_index', 'node_index']].assign(relevant=1).drop_duplicates(),\n",
    "    on = ['user_index', 'node_index'],\n",
    "    how='left' ,\n",
    ")\n",
    "df_preds_top_poplular['relevant'] = df_preds_top_poplular['relevant'].fillna(0)\n",
    "\n",
    "hitrate = calc_hitrate(df_preds_top_poplular, K)\n",
    "hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a42c346-6dc9-499a-8b09-5a8d88b6fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006796601699150424"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec = calc_prec(df_preds_top_poplular, 30)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a82f82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/18', creation_time=1716048375923, experiment_id='18', last_update_time=1716048375923, lifecycle_stage='active', name='homework-mekiselev', tags={}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заводим mlflow\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('http://84.201.128.89:90/')\n",
    "mlflow.set_experiment('homework-mekiselev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "789d4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            'hitrate': hitrate, \n",
    "            'prec': prec,\n",
    "        },\n",
    "    )\n",
    "    # mlflow.log_params( # у базелина (топ-100) параметров нет\n",
    "    #     {\n",
    "        # 'BATCH_SIZE': BATCH_SIZE,\n",
    "        # 'NUM_NEGATIVES': NUM_NEGATIVES,\n",
    "        # 'EDIM': EDIM,\n",
    "        # 'EPOCH': EPOCH,\n",
    "        # 'OPTIMIZER_NAME': OPTIMIZER_NAME,\n",
    "        # 'LR': EPOCH,\n",
    "        # }\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69087ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
